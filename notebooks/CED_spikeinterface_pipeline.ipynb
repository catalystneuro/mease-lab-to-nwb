{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpikeInterface pipeline for Mease Lab - CED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import spikeextractors as se\n",
    "import spiketoolkit as st\n",
    "import spikesorters as ss\n",
    "import spikecomparison as sc\n",
    "import spikewidgets as sw\n",
    "from nwb_conversion_tools.conversion_tools import save_si_object\n",
    "\n",
    "from mease_lab_to_nwb.convert_ced.cednwbconverter import CEDNWBConverter, quick_write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Load CED recording, set channel locations, compute LFP, and inspect signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ced_file = Path('/Users/abuccino/Documents/Data/catalyst/heidelberg/ced/m365_pt1_590-1190secs-001.smrx')\n",
    "ced_file = Path('D:/CED_example_data/Other example/m365_pt1_590-1190secs-001.smrx')\n",
    "spikeinterface_folder = Path('spikeinterface')\n",
    "spikeinterface_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically select Rhd channels\n",
    "channel_info = se.CEDRecordingExtractor.get_all_channels_info(ced_file)\n",
    "\n",
    "rhd_channels = []\n",
    "for ch, info in channel_info.items():\n",
    "    if \"Rhd\" in info[\"title\"]:\n",
    "        rhd_channels.append(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = se.CEDRecordingExtractor(ced_file, smrx_channel_ids=rhd_channels)\n",
    "\n",
    "prb_channels = [\n",
    "    42, 36, 32, 38, 39, 47, 45, 37, 44, 46, 48, 35, 34, 40, 41, 43, 62, 60, 58, 56, 54, 52, 50, 33, 49, 51, 53,\n",
    "    55, 57, 59, 61, 63, 1, 3, 5, 7, 9, 11, 13, 30, 14, 12, 10, 8, 6, 4, 2, 0, 21, 27, 31, 25, 24, 16, 18, 26,\n",
    "    19, 17, 15, 28, 29, 23, 22, 20\n",
    "]\n",
    "prb_locations = [[0, x * 20] for x in range(len(prb_channels))]\n",
    "recording.set_channel_locations(locations=np.array(prb_locations)[prb_channels, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stub recording for fast testing; set to False for running processing pipeline on entire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stub_test = True\n",
    "nsec_stub = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Num channels: {recording.get_num_channels()}\")\n",
    "print(f\"Sampling rate: {recording.get_sampling_frequency()}\")\n",
    "print(f\"Duration (s): {recording.get_num_frames() / recording.get_sampling_frequency()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load LFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_channels = []\n",
    "for ch, info in channel_info.items():\n",
    "    if \"LFP\" in info[\"title\"]:\n",
    "        lfp_channels.append(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_lfp = se.CEDRecordingExtractor(ced_file, smrx_channel_ids=lfp_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sampling frequency AP: {recording.get_sampling_frequency()}\")\n",
    "print(f\"Sampling frequency LF: {recording_lfp.get_sampling_frequency()}\")      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Resample LFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_lfp = st.preprocessing.resample(recording_lfp, resample_rate=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ts_ap = sw.plot_timeseries(recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ts_lf = sw.plot_timeseries(recording_lfp, trange=[30, 40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_filter = False # the CED data appear to be already filtered\n",
    "apply_cmr = True\n",
    "freq_min_hp = 300\n",
    "freq_max_hp = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if apply_filter:\n",
    "    recording_processed = st.preprocessing.bandpass_filter(recording, freq_min=freq_min_hp, freq_max=freq_max_hp)\n",
    "else:\n",
    "    recording_processed = recording\n",
    "    \n",
    "if apply_cmr:\n",
    "    recording_processed = st.preprocessing.common_reference(recording_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stub_test:\n",
    "    recording_processed = se.SubRecordingExtractor(recording_processed, end_frame=int(nsec_stub*recording_processed.get_sampling_frequency()))\n",
    "    recording_lfp = se.SubRecordingExtractor(recording_lfp, end_frame=int(nsec_stub*recording_lfp.get_sampling_frequency()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = recording_processed.get_num_frames()\n",
    "print(num_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ts_ap = sw.plot_timeseries(recording_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Run spike sorters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorter_list = [\n",
    "    \"ironclust\",\n",
    "    \"waveclus\",\n",
    "    # 'klusta'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.installed_sorters()\n",
    "ss.IronClustSorter.set_ironclust_path(\"D:/GitHub/ironclust\")\n",
    "ss.WaveClusSorter.set_waveclus_path(\"D:/GitHub/wave_clus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect sorter-specific parameters and defaults\n",
    "for sorter in sorter_list:\n",
    "    print(f\"\\n\\n{sorter} params description:\")\n",
    "    pprint(ss.get_params_description(sorter))\n",
    "    print(\"Default params:\")\n",
    "    pprint(ss.get_default_params(sorter))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-specific parameters\n",
    "# sorter_params = dict(kilosort2=dict(car=False),\n",
    "#                      ironclust=dict(),\n",
    "#                      spykingcircus=dict())\n",
    "sorter_params = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.run_sorter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_outputs = ss.run_sorters(\n",
    "    sorter_list=sorter_list, \n",
    "    working_folder=spikeinterface_folder / 'ced_si_output',\n",
    "    recording_dict_or_list=dict(rec0=recording_processed), \n",
    "    sorter_params=sorter_params,\n",
    "    mode=\"keep\", # change to \"keep\" to avoid repeating the spike sorting\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sorting_outputs` is a dictionary with (\"rec_name\", \"sorter_name\") as keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result_name, sorting in sorting_outputs.items():\n",
    "    rec_name, sorter = result_name\n",
    "    print(f\"{sorter} found {len(sorting.get_unit_ids())} units\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Post-processing: extract waveforms, templates, quality metrics, extracellular features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set postprocessing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing params\n",
    "postprocessing_params = st.postprocessing.get_common_params()\n",
    "pprint(postprocessing_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) change parameters\n",
    "postprocessing_params['max_spikes_per_unit'] = 1000  # with None, all waveforms are extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set quality metric list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality metrics\n",
    "qc_list = st.validation.get_quality_metrics_list()\n",
    "print(f\"Available quality metrics: {qc_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) define subset of qc\n",
    "qc_list = ['snr', 'isi_violation', 'firing_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set extracellular features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracellular features\n",
    "ec_list = st.postprocessing.get_template_features_list()\n",
    "print(f\"Available EC features: {ec_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) define subset of ec\n",
    "ec_list = ['peak_to_valley', 'halfwidth']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postprocess all sorting outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result_name, sorting in sorting_outputs.items():\n",
    "    rec_name, sorter = result_name\n",
    "    print(f\"Postprocessing recording {rec_name} sorted with {sorter}\")\n",
    "    tmp_folder = Path('tmp_ced') / sorter\n",
    "    tmp_folder.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # set local tmp folder\n",
    "    sorting.set_tmp_folder(tmp_folder)\n",
    "    \n",
    "    # compute waveforms\n",
    "    waveforms = st.postprocessing.get_unit_waveforms(recording_processed, sorting, \n",
    "                                                     **postprocessing_params)\n",
    "    \n",
    "    # compute templates\n",
    "    templates = st.postprocessing.get_unit_templates(recording_processed, sorting, **postprocessing_params)\n",
    "    \n",
    "    # comput EC features\n",
    "    ec = st.postprocessing.compute_unit_template_features(recording_processed, sorting,\n",
    "                                                          feature_names=ec_list, as_dataframe=True)\n",
    "    # compute QCs\n",
    "    qc = st.validation.compute_quality_metrics(sorting, recording=recording_processed, \n",
    "                                               metric_names=qc_list, as_dataframe=True)\n",
    "    \n",
    "    # export to phy\n",
    "    phy_folder = spikeinterface_folder / 'phy' / sorter\n",
    "    phy_folder.mkdir(parents=True, exist_ok=True)\n",
    "    print(\"Exporting to phy\")\n",
    "    st.postprocessing.export_to_phy(recording_processed, sorting, phy_folder, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Phy-curated data back to SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!phy template-gui spikeinterface/phy/ironclust/params.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phy_folder = 'spikeinterface/phy/ironclust/'\n",
    "sorting_curated = se.PhySortingExtractor(phy_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Ensemble spike sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sorting_outputs) > 1:\n",
    "    # retrieve sortings and sorter names\n",
    "    sorting_list = []\n",
    "    sorter_names_comp = []\n",
    "    for result_name, sorting in sorting_outputs.items():\n",
    "        rec_name, sorter = result_name\n",
    "        sorting_list.append(sorting)\n",
    "        sorter_names_comp.append(sorter)\n",
    "        \n",
    "    # run multisorting comparison\n",
    "    mcmp = sc.compare_multiple_sorters(sorting_list=sorting_list, name_list=sorter_names_comp)\n",
    "    \n",
    "    # plot agreement results\n",
    "    w_agr = sw.plot_multicomp_agreement(mcmp)\n",
    "    \n",
    "    # extract ensamble sorting\n",
    "    sorting_ensemble = mcmp.get_agreement_sorting(minimum_agreement_count=2)\n",
    "    \n",
    "    print(f\"Ensemble sorting among {sorter_list} found: {len(sorting_ensemble.get_unit_ids())} units\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) save ensemble output for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_si_object(\n",
    "    \"sorting_ensemble\", sorting_ensemble, spikeinterface_folder,\n",
    "    cache_raw=False, include_properties=True, include_features=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Automatic curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define curators and thresholds\n",
    "isi_violation_threshold = 0.5\n",
    "snr_threshold = 3\n",
    "firing_rate_threshold = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_auto_curated = []\n",
    "sorter_names_curation = []\n",
    "for result_name, sorting in sorting_outputs.items():\n",
    "    rec_name, sorter = result_name\n",
    "    sorter_names_curation.append(sorter)\n",
    "    \n",
    "    # firing rate threshold\n",
    "    sorting_curated = st.curation.threshold_firing_rates(sorting, duration_in_frames=num_frames,\n",
    "                                                         threshold=firing_rate_threshold, \n",
    "                                                         threshold_sign='less')\n",
    "    \n",
    "    # isi violation threshold\n",
    "    sorting_curated = st.curation.threshold_isi_violations(sorting, duration_in_frames=num_frames,\n",
    "                                                           threshold=isi_violation_threshold, \n",
    "                                                           threshold_sign='greater')\n",
    "    \n",
    "    # isi violation threshold\n",
    "    sorting_curated = st.curation.threshold_snrs(sorting, recording=recording_processed,\n",
    "                                                 threshold=snr_threshold, \n",
    "                                                 threshold_sign='less')\n",
    "    sorting_auto_curated.append(sorting_curated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorting_auto_curated[0].get_unit_ids())\n",
    "print(sorting_auto_curated[1].get_unit_ids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Quick save to NWB; writes only the spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To complete the full conversion for other types of data, use the external script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name your NWBFile and decide where you want it saved\n",
    "nwbfile_path = ced_file.parent / \"CED.nwb\"\n",
    "\n",
    "# Enter Session and Subject information here\n",
    "session_description = \"Enter session description here.\"\n",
    "\n",
    "# Manually insert the session start time\n",
    "session_start = datetime(1971, 1, 1, 1, 1, 1)  # (Year, Month, Day, Hour, Minute, Second)\n",
    "\n",
    "# Choose the sorting extractor from the notebook environment you would like to write to NWB\n",
    "chosen_sorting_extractor = sorting_outputs[('rec0', 'ironclust')]\n",
    "\n",
    "quick_write(\n",
    "    ced_file_path=ced_file,\n",
    "    session_description=session_description,\n",
    "    session_start=session_start,\n",
    "    save_path=nwbfile_path,\n",
    "    sorting=chosen_sorting_extractor,\n",
    "    recording_lfp=recording_lfp,\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Full Save to NWB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name your NWBFile and decide where you want it saved\n",
    "nwbfile_path = ced_file.parent / \"CED.nwb\"\n",
    "\n",
    "# Choose the sorting extractor from the notebook environment you would like to write to NWB\n",
    "chosen_sorting_extractor = sorting_outputs[('rec0', 'ironclust')]\n",
    "\n",
    "# If you do not want to include the LFP data from the recording, comment out this variable\n",
    "chosen_recording_lfp = recording_lfp\n",
    "\n",
    "# Enter Session and Subject information here\n",
    "session_description = \"Enter session description here.\"\n",
    "\n",
    "# Manually insert the session start time\n",
    "session_start = datetime(1971, 1, 1, 1, 1, 1)  # (Year, Month, Day, Hour, Minute, Second)\n",
    "\n",
    "# Uncomment any fields you want to include\n",
    "subject_info = dict(\n",
    "    subject_id=\"Enter optional subject id here\",\n",
    "#    description=\"Enter optional subject description here\",\n",
    "#    weight=\"Enter subject weight here\",\n",
    "#    age=duration_isoformat(timedelta(days=0)),  # Enter the age of the subject in days\n",
    "#    species=\"Mus musculus\",\n",
    "#    genotype=\"Enter subject genotype here\",\n",
    "#    sex=\"Enter subject sex here\"\n",
    ")\n",
    "\n",
    "# Set some global conversion options here\n",
    "# It's recommended to set stub_test to True on first attempt to ensure NWBFile output looks OK\n",
    "conversion_stub_test = True\n",
    "overwrite = True  # If the NWBFile exists at the path, replace it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this cell to automatically perform conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically performs conversion based on above filepaths and options\n",
    "source_data = dict(\n",
    "    CEDRecording=dict(file_path=str(ced_file)),\n",
    "    CEDStimulus=dict(file_path=str(ced_file))\n",
    ")\n",
    "conversion_options = dict(\n",
    "    CEDRecording=dict(stub_test=conversion_stub_test),\n",
    "    CEDStimulus=dict(stub_test=conversion_stub_test)\n",
    ")\n",
    "converter = CEDNWBConverter(source_data)\n",
    "metadata = converter.get_metadata()\n",
    "metadata['NWBFile'].update(session_description=session_description, session_start_time=session_start.astimezone())\n",
    "metadata.update(Subject=subject_info)\n",
    "run_args = dict(\n",
    "    nwbfile_path=str(nwbfile_path),\n",
    "    metadata=metadata,\n",
    "    save_to_file=True,\n",
    "    conversion_options=conversion_options,\n",
    "    sorting=chosen_sorting_extractor,\n",
    "    overwrite=overwrite\n",
    ")\n",
    "if \"chosen_recording_lfp\" in locals():\n",
    "    run_args.update(recording_lfp=chosen_recording_lfp)\n",
    "converter.run_conversion(**run_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
